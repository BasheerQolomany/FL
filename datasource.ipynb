{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"datasource.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"86_69UizR8x3","colab_type":"code","colab":{}},"source":["import numpy as np\n","import keras\n","import random\n","from keras.datasets import mnist\n","from keras import backend as K\n","\n","class DataSource(object):\n","    def __init__(self):\n","        raise NotImplementedError()\n","    def partitioned_by_rows(self, num_workers, test_reserve=.3):\n","        raise NotImplementedError()\n","    def sample_single_non_iid(self, weight=None):\n","        raise NotImplementedError()\n","\n","\n","class Mnist(DataSource):\n","\n","    IID = False\n","    MAX_NUM_CLASSES_PER_CLIENT = 5\n","    \n","    def __init__(self):\n","        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n","        self.x = np.concatenate([x_train, x_test]).astype('float')\n","        self.y = np.concatenate([y_train, y_test])\n","        n = self.x.shape[0]\n","        idx = np.arange(n)\n","        np.random.shuffle(idx)\n","        self.x = self.x[idx]  # n * 28 * 28\n","        self.y = self.y[idx]  # n * 1\n","        data_split = (0.6, 0.3, 0.1)\n","        num_train = int(n * data_split[0])\n","        num_test = int(n * data_split[1])\n","        self.x_train = self.x[0:num_train]\n","        self.x_test = self.x[num_train:num_train + num_test]\n","        self.x_valid = self.x[num_train + num_test:]\n","        self.y_train = self.y[0:num_train]\n","        self.y_test = self.y[num_train:num_train + num_test]\n","        self.y_valid = self.y[num_train + num_test:]\n","        self.classes = np.unique(self.y)\n","    \n","    def gen_dummy_non_iid_weights(self):\n","        self.classes = np.array(range(10))\n","        num_classes_this_client = random.randint(1, Mnist.MAX_NUM_CLASSES_PER_CLIENT + 1)\n","        classes_this_client = random.sample(self.classes.tolist(), num_classes_this_client)\n","        w = np.array([random.random() for _ in range(num_classes_this_client)])\n","        weights = np.array([0.] * self.classes.shape[0])\n","        for i in range(len(classes_this_client)):\n","            weights[classes_this_client[i]] = w[i]\n","        weights /= np.sum(weights)\n","        return weights.tolist()\n","\n","\n","    # assuming client server already agreed on data format\n","    def post_process(self, xi, yi):\n","        if K.image_data_format() == 'channels_first':\n","            xi = xi.reshape(1, xi.shape[0], xi.shape[1])\n","        else:\n","            xi = xi.reshape(xi.shape[0], xi.shape[1], 1)\n","\n","        y_vec = keras.utils.to_categorical(yi, self.classes.shape[0])\n","        return xi / 255., y_vec\n","\n","    # split evenly into exact num_workers chunks, with test_reserve globally\n","    def partitioned_by_rows(self, num_workers, test_reserve=.3):\n","        n_test = int(self.x.shape[0] * test_reserve)\n","        n_train = self.x.shape[0] - n_test\n","        nums = [n_train // num_workers] * num_workers\n","        nums[-1] += n_train % num_workers\n","        idxs = np.array([np.random.choice(np.arange(n_train), num, replace=False) for num in nums])\n","        return {\n","            # (size_partition * 28 * 28, size_partition * 1) * num_partitions\n","            \"train\": [post_process(self.x[idx], self.y[idx]) for idx in idxs],\n","            # (n_test * 28 * 28, n_test * 1)\n","            \"test\": post_process(self.x[np.arange(n_train, n_train + n_test)], self.y[np.arange(n_train, n_train + n_test)])\n","        }\n","\n","    # Generate one sample from all available data, *with replacement*.\n","    # This is to simulate date generation on a client.\n","    # weight: [probablity of classes]\n","    # returns: 28 * 28, 1\n","    def sample_single_non_iid(self, x, y, weight=None):\n","        # first pick class, then pick a datapoint at random\n","        chosen_class = np.random.choice(self.classes, p=weight)\n","        candidates_idx = np.array([i for i in range(y.shape[0]) if y[i] == chosen_class])\n","        idx = np.random.choice(candidates_idx)\n","        return self.post_process(x[idx], y[idx])\n","\n","    \n","    # generate t, t, v dataset given distribution and split\n","    def fake_non_iid_data(self, min_train=100, max_train=1000, data_split=(.6,.3,.1)):        \n","        # my_class_distr = np.array([np.random.random() for _ in range(self.classes.shape[0])])\n","        # my_class_distr /= np.sum(my_class_distr)\n","        my_class_distr = [1. / self.classes.shape[0] * self.classes.shape[0]] if Mnist.IID \\\n","                else self.gen_dummy_non_iid_weights()\n","        \n","        train_size = random.randint(min_train, max_train)\n","        test_size = int(train_size / data_split[0] * data_split[1])\n","        valid_size = int(train_size / data_split[0] * data_split[2])\n","\n","        train_set = [self.sample_single_non_iid(self.x_train, self.y_train, my_class_distr) for _ in range(train_size)]\n","        test_set = [self.sample_single_non_iid(self.x_test, self.y_test, my_class_distr) for _ in range(test_size)]\n","        valid_set = [self.sample_single_non_iid(self.x_valid, self.y_valid, my_class_distr) for _ in range(valid_size)]\n","        print(\"done generating fake data\")\n","\n","        return ((train_set, test_set, valid_set), my_class_distr)\n","\n","\n","if __name__ == \"__main__\":\n","    m = Mnist()\n","    # res = m.partitioned_by_rows(9)\n","    # print(res[\"test\"][1].shape)\n","    for _ in range(10):\n","        print(m.gen_dummy_non_iid_weights())\n","\n"],"execution_count":0,"outputs":[]}]}