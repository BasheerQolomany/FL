{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fl_server.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Tgh1xgSKRgjW","colab_type":"code","colab":{}},"source":["import pickle\n","import keras\n","import uuid\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","\n","import msgpack\n","import random\n","import codecs\n","import numpy as np\n","import json\n","import msgpack_numpy\n","# https://github.com/lebedov/msgpack-numpy\n","\n","import sys\n","import time\n","\n","from flask import *\n","from flask_socketio import SocketIO\n","from flask_socketio import *\n","# https://flask-socketio.readthedocs.io/en/latest/\n","       \n","\n","class GlobalModel(object):\n","    \"\"\"docstring for GlobalModel\"\"\"\n","    def __init__(self):\n","        self.model = self.build_model()\n","        self.current_weights = self.model.get_weights()\n","        # for convergence check\n","        self.prev_train_loss = None\n","\n","        # all rounds; losses[i] = [round#, timestamp, loss]\n","        # round# could be None if not applicable\n","        self.train_losses = []\n","        self.valid_losses = []\n","        self.train_accuracies = []\n","        self.valid_accuracies = []\n","\n","        self.training_start_time = int(round(time.time()))\n","    \n","    def build_model(self):\n","        raise NotImplementedError()\n","\n","    # client_updates = [(w, n)..]\n","    def update_weights(self, client_weights, client_sizes):\n","        new_weights = [np.zeros(w.shape) for w in self.current_weights]\n","        total_size = np.sum(client_sizes)\n","\n","        for c in range(len(client_weights)):\n","            for i in range(len(new_weights)):\n","                new_weights[i] += client_weights[c][i] * client_sizes[c] / total_size\n","        self.current_weights = new_weights        \n","\n","    def aggregate_loss_accuracy(self, client_losses, client_accuracies, client_sizes):\n","        total_size = np.sum(client_sizes)\n","        # weighted sum\n","        aggr_loss = np.sum(client_losses[i] / total_size * client_sizes[i]\n","                for i in range(len(client_sizes)))\n","        aggr_accuraries = np.sum(client_accuracies[i] / total_size * client_sizes[i]\n","                for i in range(len(client_sizes)))\n","        return aggr_loss, aggr_accuraries\n","\n","    # cur_round coule be None\n","    def aggregate_train_loss_accuracy(self, client_losses, client_accuracies, client_sizes, cur_round):\n","        cur_time = int(round(time.time())) - self.training_start_time\n","        aggr_loss, aggr_accuraries = self.aggregate_loss_accuracy(client_losses, client_accuracies, client_sizes)\n","        self.train_losses += [[cur_round, cur_time, aggr_loss]]\n","        self.train_accuracies += [[cur_round, cur_time, aggr_accuraries]]\n","        with open('stats.txt', 'w') as outfile:\n","            json.dump(self.get_stats(), outfile)\n","        return aggr_loss, aggr_accuraries\n","\n","    # cur_round coule be None\n","    def aggregate_valid_loss_accuracy(self, client_losses, client_accuracies, client_sizes, cur_round):\n","        cur_time = int(round(time.time())) - self.training_start_time\n","        aggr_loss, aggr_accuraries = self.aggregate_loss_accuracy(client_losses, client_accuracies, client_sizes)\n","        self.valid_losses += [[cur_round, cur_time, aggr_loss]]\n","        self.valid_accuracies += [[cur_round, cur_time, aggr_accuraries]]\n","        with open('stats.txt', 'w') as outfile:\n","            json.dump(self.get_stats(), outfile)\n","        return aggr_loss, aggr_accuraries\n","\n","    def get_stats(self):\n","        return {\n","            \"train_loss\": self.train_losses,\n","            \"valid_loss\": self.valid_losses,\n","            \"train_accuracy\": self.train_accuracies,\n","            \"valid_accuracy\": self.valid_accuracies\n","        }\n","        \n","\n","class GlobalModel_MNIST_CNN(GlobalModel):\n","    def __init__(self):\n","        super(GlobalModel_MNIST_CNN, self).__init__()\n","\n","    def build_model(self):\n","        # ~5MB worth of parameters\n","        model = Sequential()\n","        model.add(Conv2D(32, kernel_size=(3, 3),\n","                         activation='relu',\n","                         input_shape=(28, 28, 1)))\n","        model.add(Conv2D(64, (3, 3), activation='relu'))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","        model.add(Dropout(0.25))\n","        model.add(Flatten())\n","        model.add(Dense(128, activation='relu'))\n","        model.add(Dropout(0.5))\n","        model.add(Dense(10, activation='softmax'))\n","\n","        model.compile(loss=keras.losses.categorical_crossentropy,\n","                      optimizer=keras.optimizers.Adadelta(),\n","                      metrics=['accuracy'])\n","        return model\n","\n","        \n","######## Flask server with Socket IO ########\n","\n","# Federated Averaging algorithm with the server pulling from clients\n","\n","class FLServer(object):\n","    \n","    MIN_NUM_WORKERS = 5\n","    MAX_NUM_ROUNDS = 50\n","    NUM_CLIENTS_CONTACTED_PER_ROUND = 5\n","    ROUNDS_BETWEEN_VALIDATIONS = 2\n","\n","    def __init__(self, global_model, host, port):\n","        self.global_model = global_model()\n","\n","        self.ready_client_sids = set()\n","\n","        self.app = Flask(__name__)\n","        self.socketio = SocketIO(self.app)\n","        self.host = host\n","        self.port = port\n","\n","        self.model_id = str(uuid.uuid4())\n","\n","        #####\n","        # training states\n","        self.current_round = -1  # -1 for not yet started\n","        self.current_round_client_updates = []\n","        self.eval_client_updates = []\n","        #####\n","\n","        # socket io messages\n","        self.register_handles()\n","\n","\n","        @self.app.route('/')\n","        def dashboard():\n","            return render_template('dashboard.html')\n","\n","        @self.app.route('/stats')\n","        def status_page():\n","            return json.dumps(self.global_model.get_stats())\n","\n","        \n","    def register_handles(self):\n","        # single-threaded async, no need to lock\n","\n","        @self.socketio.on('connect')\n","        def handle_connect():\n","            print(request.sid, \"connected\")\n","\n","        @self.socketio.on('reconnect')\n","        def handle_reconnect():\n","            print(request.sid, \"reconnected\")\n","\n","        @self.socketio.on('disconnect')\n","        def handle_reconnect():\n","            print(request.sid, \"disconnected\")\n","            if request.sid in self.ready_client_sids:\n","                self.ready_client_sids.remove(request.sid)\n","\n","        @self.socketio.on('client_wake_up')\n","        def handle_wake_up():\n","            print(\"client wake_up: \", request.sid)\n","            emit('init', {\n","                    'model_json': self.global_model.model.to_json(),\n","                    'model_id': self.model_id,\n","                    'min_train_size': 1200,\n","                    'data_split': (0.6, 0.3, 0.1), # train, test, valid\n","                    'epoch_per_round': 1,\n","                    'batch_size': 10\n","                })\n","\n","        @self.socketio.on('client_ready')\n","        def handle_client_ready(data):\n","            print(\"client ready for training\", request.sid, data)\n","            self.ready_client_sids.add(request.sid)\n","            if len(self.ready_client_sids) >= FLServer.MIN_NUM_WORKERS and self.current_round == -1:\n","                self.train_next_round()\n","\n","        @self.socketio.on('client_update')\n","        def handle_client_update(data):\n","            print(\"received client update of bytes: \", sys.getsizeof(data))\n","            print(\"handle client_update\", request.sid)\n","            for x in data:\n","                if x != 'weights':\n","                    print(x, data[x])\n","            # data:\n","            #   weights\n","            #   train_size\n","            #   valid_size\n","            #   train_loss\n","            #   train_accuracy\n","            #   valid_loss?\n","            #   valid_accuracy?\n","\n","            # discard outdated update\n","            if data['round_number'] == self.current_round:\n","                self.current_round_client_updates += [data]\n","                self.current_round_client_updates[-1]['weights'] = pickle_string_to_obj(data['weights'])\n","                \n","                # tolerate 30% unresponsive clients\n","                if len(self.current_round_client_updates) > FLServer.NUM_CLIENTS_CONTACTED_PER_ROUND * .7:\n","                    self.global_model.update_weights(\n","                        [x['weights'] for x in self.current_round_client_updates],\n","                        [x['train_size'] for x in self.current_round_client_updates],\n","                    )\n","                    aggr_train_loss, aggr_train_accuracy = self.global_model.aggregate_train_loss_accuracy(\n","                        [x['train_loss'] for x in self.current_round_client_updates],\n","                        [x['train_accuracy'] for x in self.current_round_client_updates],\n","                        [x['train_size'] for x in self.current_round_client_updates],\n","                        self.current_round\n","                    )\n","\n","                    print(\"aggr_train_loss\", aggr_train_loss)\n","                    print(\"aggr_train_accuracy\", aggr_train_accuracy)\n","\n","                    if 'valid_loss' in self.current_round_client_updates[0]:\n","                        aggr_valid_loss, aggr_valid_accuracy = self.global_model.aggregate_valid_loss_accuracy(\n","                            [x['valid_loss'] for x in self.current_round_client_updates],\n","                            [x['valid_accuracy'] for x in self.current_round_client_updates],\n","                            [x['valid_size'] for x in self.current_round_client_updates],\n","                            self.current_round\n","                        )\n","                        print(\"aggr_valid_loss\", aggr_valid_loss)\n","                        print(\"aggr_valid_accuracy\", aggr_valid_accuracy)\n","\n","                    if self.global_model.prev_train_loss is not None and \\\n","                            (self.global_model.prev_train_loss - aggr_train_loss) / self.global_model.prev_train_loss < .01:\n","                        # converges\n","                        print(\"converges! starting test phase..\")\n","                        self.stop_and_eval()\n","                        return\n","                    \n","                    self.global_model.prev_train_loss = aggr_train_loss\n","\n","                    if self.current_round >= FLServer.MAX_NUM_ROUNDS:\n","                        self.stop_and_eval()\n","                    else:\n","                        self.train_next_round()\n","\n","        @self.socketio.on('client_eval')\n","        def handle_client_eval(data):\n","            if self.eval_client_updates is None:\n","                return\n","            print(\"handle client_eval\", request.sid)\n","            print(\"eval_resp\", data)\n","            self.eval_client_updates += [data]\n","\n","            # tolerate 30% unresponsive clients\n","            if len(self.eval_client_updates) > FLServer.NUM_CLIENTS_CONTACTED_PER_ROUND * .7:\n","                aggr_test_loss, aggr_test_accuracy = self.global_model.aggregate_loss_accuracy(\n","                    [x['test_loss'] for x in self.eval_client_updates],\n","                    [x['test_accuracy'] for x in self.eval_client_updates],\n","                    [x['test_size'] for x in self.eval_client_updates],\n","                );\n","                print(\"\\naggr_test_loss\", aggr_test_loss)\n","                print(\"aggr_test_accuracy\", aggr_test_accuracy)\n","                print(\"== done ==\")\n","                self.eval_client_updates = None  # special value, forbid evaling again\n","\n","    \n","    # Note: we assume that during training the #workers will be >= MIN_NUM_WORKERS\n","    def train_next_round(self):\n","        self.current_round += 1\n","        # buffers all client updates\n","        self.current_round_client_updates = []\n","\n","        print(\"### Round \", self.current_round, \"###\")\n","        client_sids_selected = random.sample(list(self.ready_client_sids), FLServer.NUM_CLIENTS_CONTACTED_PER_ROUND)\n","        print(\"request updates from\", client_sids_selected)\n","\n","        # by default each client cnn is in its own \"room\"\n","        for rid in client_sids_selected:\n","            emit('request_update', {\n","                    'model_id': self.model_id,\n","                    'round_number': self.current_round,\n","                    'current_weights': obj_to_pickle_string(self.global_model.current_weights),\n","\n","                    'weights_format': 'pickle',\n","                    'run_validation': self.current_round % FLServer.ROUNDS_BETWEEN_VALIDATIONS == 0,\n","                }, room=rid)\n","\n","    \n","    def stop_and_eval(self):\n","        self.eval_client_updates = []\n","        for rid in self.ready_client_sids:\n","            emit('stop_and_eval', {\n","                    'model_id': self.model_id,\n","                    'current_weights': obj_to_pickle_string(self.global_model.current_weights),\n","                    'weights_format': 'pickle'\n","                }, room=rid)\n","\n","    def start(self):\n","        self.socketio.run(self.app, host=self.host, port=self.port)\n","\n","\n","\n","def obj_to_pickle_string(x):\n","    return codecs.encode(pickle.dumps(x), \"base64\").decode()\n","    # return msgpack.packb(x, default=msgpack_numpy.encode)\n","    # TODO: compare pickle vs msgpack vs json for serialization; tradeoff: computation vs network IO\n","\n","def pickle_string_to_obj(s):\n","    return pickle.loads(codecs.decode(s.encode(), \"base64\"))\n","    # return msgpack.unpackb(s, object_hook=msgpack_numpy.decode)\n","\n","\n","if __name__ == '__main__':\n","    # When the application is in debug mode the Werkzeug development server is still used\n","    # and configured properly inside socketio.run(). In production mode the eventlet web server\n","    # is used if available, else the gevent web server is used.\n","    \n","    server = FLServer(GlobalModel_MNIST_CNN, \"127.0.0.1\", 5000)\n","    print(\"listening on 127.0.0.1:5000\");\n","    server.start()\n"],"execution_count":0,"outputs":[]}]}